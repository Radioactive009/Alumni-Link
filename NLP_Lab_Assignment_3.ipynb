{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0KG3HT6HUMZ3UI7qPnm7q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Radioactive009/Alumni-Link/blob/main/NLP_Lab_Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxfliJDM9f2h",
        "outputId": "321b0daa-c86f-4fe7-bb11-af92e06984ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "import string\n",
        "import math\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('brown')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import brown\n",
        "\n",
        "sentences = brown.sents()\n"
      ],
      "metadata": {
        "id": "SfxLCuzo_oGQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1.2 - Preprocess Text"
      ],
      "metadata": {
        "id": "PYBgPBe0AwY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(sentences):\n",
        "    tokens = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        for word in sentence:\n",
        "            word = word.lower()\n",
        "\n",
        "            # Remove punctuation\n",
        "            if word not in string.punctuation:\n",
        "                tokens.append(word)\n",
        "\n",
        "    return tokens\n",
        "\n",
        "tokens = preprocess(sentences)\n",
        "\n",
        "print(\"Total words after preprocessing:\", len(tokens))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ep_Yevr_rjh",
        "outputId": "3e82332a-e4fd-4c73-a939-acaa89c4c498"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words after preprocessing: 1034378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2(a) -  Count Word Frequencies"
      ],
      "metadata": {
        "id": "502sCPy8_vlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_counts = Counter(tokens)\n",
        "\n",
        "print(\"Top 10 words:\")\n",
        "print(word_counts.most_common(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnFhdNb8_5GY",
        "outputId": "1426e01f-7c71-408d-86fb-6d218190ed13"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 words:\n",
            "[('the', 69971), ('of', 36412), ('and', 28853), ('to', 26158), ('a', 23195), ('in', 21337), ('that', 10594), ('is', 10109), ('was', 9815), ('he', 9548)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2(b) - Calculate unigram probability\n",
        "P(w) = Count(w)/Total Words"
      ],
      "metadata": {
        "id": "dwRoMU0bCz3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_words = len(tokens)\n",
        "\n",
        "unigram_prob = {}\n",
        "\n",
        "for word in word_counts:\n",
        "    unigram_prob[word] = word_counts[word] / total_words\n"
      ],
      "metadata": {
        "id": "FPMv6X6ADAU6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2(c) - Compute Sentence Probability"
      ],
      "metadata": {
        "id": "GE3Gfw4tDETw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"the government is working\"\n",
        "def sentence_probability_unigram(sentence):\n",
        "    words = sentence.lower().split()\n",
        "    prob = 1\n",
        "\n",
        "    for word in words:\n",
        "        if word in unigram_prob:\n",
        "            prob *= unigram_prob[word]\n",
        "        else:\n",
        "            prob *= 1e-6  # small value for unknown word\n",
        "\n",
        "    return prob\n",
        "\n",
        "print(\"Unigram Sentence Probability:\",\n",
        "      sentence_probability_unigram(sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_W3fpQTDHx9",
        "outputId": "dad0c91b-1c12-430d-c908-2a6285d1ab63"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Sentence Probability: 3.8999802363629654e-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3 - Bigram Model"
      ],
      "metadata": {
        "id": "jHpf0EHkDUk1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3(a) - Generate Bigram Pairs"
      ],
      "metadata": {
        "id": "n936uO0_DcNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_bigrams(tokens):\n",
        "    bigrams = []\n",
        "    for i in range(len(tokens)-1):\n",
        "        bigrams.append((tokens[i], tokens[i+1]))\n",
        "    return bigrams\n",
        "\n",
        "bigrams = generate_bigrams(tokens)\n"
      ],
      "metadata": {
        "id": "m9bmiMljDgkM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Counting Bigram frequencies\n",
        "def generate_bigrams(tokens):\n",
        "    bigrams = []\n",
        "    for i in range(len(tokens)-1):\n",
        "        bigrams.append((tokens[i], tokens[i+1]))\n",
        "    return bigrams\n",
        "\n",
        "bigrams = generate_bigrams(tokens)\n"
      ],
      "metadata": {
        "id": "PtZN_MHeDmRa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3b. Compute Bigram Probabilities\n",
        "P(wi​∣wi−1​) = {Count(Wi-1, Wi)/Count(Wi-1)}"
      ],
      "metadata": {
        "id": "PzutA38zDtZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_prob = {}\n",
        "\n",
        "bigram_counts = Counter(bigrams)\n",
        "for (w1, w2) in bigram_counts:\n",
        "    bigram_prob[(w1, w2)] = bigram_counts[(w1, w2)] / word_counts[w1]"
      ],
      "metadata": {
        "id": "_rxDQy0zD_LX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute Sentence Probability (Bigram)\n",
        "def sentence_probability_bigram(sentence):\n",
        "    words = sentence.lower().split()\n",
        "    prob = 1\n",
        "\n",
        "    for i in range(1, len(words)):\n",
        "        if (words[i-1], words[i]) in bigram_prob:\n",
        "            prob *= bigram_prob[(words[i-1], words[i])]\n",
        "        else:\n",
        "            prob *= 1e-6\n",
        "\n",
        "    return prob\n",
        "\n",
        "print(\"Bigram Sentence Probability:\",\n",
        "      sentence_probability_bigram(sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCd1DlkhEJjP",
        "outputId": "2d0e524f-cbbb-4236-ef59-a9aeeb22383e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram Sentence Probability: 3.8989836026935755e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4 - Laplace Smoothing"
      ],
      "metadata": {
        "id": "Hrk02OBwEPpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word_counts)\n",
        "\n",
        "def sentence_probability_bigram_laplace(sentence):\n",
        "    words = sentence.lower().split()\n",
        "    prob = 1\n",
        "\n",
        "    for i in range(1, len(words)):\n",
        "        count_bigram = bigram_counts[(words[i-1], words[i])]\n",
        "        count_unigram = word_counts[words[i-1]]\n",
        "\n",
        "        prob *= (count_bigram + 1) / (count_unigram + vocab_size)\n",
        "\n",
        "    return prob\n",
        "\n",
        "print(\"Bigram with Laplace:\",\n",
        "      sentence_probability_bigram_laplace(sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w85rMz1fEVGR",
        "outputId": "1711417c-e0a9-4bfc-81f0-7c315135ce7c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram with Laplace: 3.9563483935955733e-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5 - Perplexity"
      ],
      "metadata": {
        "id": "TW7V7Ks3EXBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5.1 - Split Train, Test data"
      ],
      "metadata": {
        "id": "9f5lVE_mEcf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences = sentences[:50000]\n",
        "test_sentences = sentences[50000:51000]\n",
        "\n",
        "train_tokens = preprocess(train_sentences)\n"
      ],
      "metadata": {
        "id": "Qjng3kKMEf70"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5.2 - Compute Perplexity"
      ],
      "metadata": {
        "id": "fjdAJOCvEkXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(test_sentences):\n",
        "    log_prob = 0\n",
        "    N = 0\n",
        "\n",
        "    for sentence in test_sentences:\n",
        "        words = [w.lower() for w in sentence if w not in string.punctuation]\n",
        "\n",
        "        for i in range(1, len(words)):\n",
        "            count_bigram = bigram_counts[(words[i-1], words[i])]\n",
        "            count_unigram = word_counts[words[i-1]]\n",
        "\n",
        "            prob = (count_bigram + 1) / (count_unigram + vocab_size)\n",
        "\n",
        "            log_prob += math.log(prob)\n",
        "            N += 1\n",
        "\n",
        "    return math.exp(-log_prob / N)\n",
        "\n",
        "print(\"Perplexity:\", perplexity(test_sentences))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWScqs6TEnqk",
        "outputId": "5c2e8121-376c-497a-a3e6-5c72c6b3ffdd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity: 4752.49153940994\n"
          ]
        }
      ]
    }
  ]
}